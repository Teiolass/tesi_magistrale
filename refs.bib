
@inproceedings{
panigutti-xai,
    address={Barcelona Spain}, title={Doctor XAI: an ontology-based approach to black-box sequential data classification explanations}, ISBN={978-1-4503-6936-7}, url={https://dl.acm.org/doi/10.1145/3351095.3372855}, DOI={10.1145/3351095.3372855}, abstractNote={Several recent advancements in Machine Learning involve blackbox models: algorithms that do not provide human-understandable explanations in support of their decisions. This limitation hampers the fairness, accountability and transparency of these models; the field of eXplainable Artificial Intelligence (XAI) tries to solve this problem providing human-understandable explanations for black-box models. However, healthcare datasets (and the related learning tasks) often present peculiar features, such as sequential data, multi-label predictions, and links to structured background knowledge. In this paper, we introduce Doctor XAI, a model-agnostic explainability technique able to deal with multi-labeled, sequential, ontology-linked data. We focus on explaining Doctor AI, a multilabel classifier which takes as input the clinical history of a patient in order to predict the next visit. Furthermore, we show how exploiting the temporal dimension in the data and the domain knowledge encoded in the medical ontology improves the quality of the mined explanations.}, booktitle={Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency}, publisher={ACM}, author={Panigutti, Cecilia and Perotti, Alan and Pedreschi, Dino}, year={2020}, month=jan, pages={629–639}, language={en} }

@article{
mimic-iv-cit,
    title={MIMIC-IV, a freely accessible electronic health record dataset}, volume={10}, ISSN={2052-4463}, DOI={10.1038/s41597-022-01899-x}, abstractNote={Abstract Digital data collection during routine clinical practice is now ubiquitous within hospitals. The data contains valuable information on the care of patients and their response to treatments, offering exciting opportunities for research. Typically, data are stored within archival systems that are not intended to support research. These systems are often inaccessible to researchers and structured for optimal storage, rather than interpretability and analysis. Here we present MIMIC-IV, a publicly available database sourced from the electronic health record of the Beth Israel Deaconess Medical Center. Information available includes patient measurements, orders, diagnoses, procedures, treatments, and deidentified free-text clinical notes. MIMIC-IV is intended to support a wide array of research studies and educational material, helping to reduce barriers to conducting clinical research.}, number={1}, journal={Scientific Data}, author={Johnson, Alistair E. W. and Bulgarelli, Lucas and Shen, Lu and Gayles, Alvin and Shammout, Ayad and Horng, Steven and Pollard, Tom J. and Hao, Sicheng and Moody, Benjamin and Gow, Brian and Lehman, Li-wei H. and Celi, Leo A. and Mark, Roger G.}, year={2023}, month=jan, pages={1}, language={en} }

@article{
setor-paper,
    title={Sequential Diagnosis Prediction with Transformer and Ontological Representation}, url={http://arxiv.org/abs/2109.03069}, abstractNote={Sequential diagnosis prediction on the Electronic Health Record (EHR) has been proven crucial for predictive analytics in the medical domain. EHR data, sequential records of a patient’s interactions with healthcare systems, has numerous inherent characteristics of temporality, irregularity and data insufﬁciency. Some recent works train healthcare predictive models by making use of sequential information in EHR data, but they are vulnerable to irregular, temporal EHR data with the states of admission/discharge from hospital, and insufﬁcient data. To mitigate this, we propose an end-to-end robust transformer-based model called SETOR, which exploits neural ordinary differential equation to handle both irregular intervals between a patient’s visits with admitted timestamps and length of stay in each visit, to alleviate the limitation of insufﬁcient data by integrating medical ontology, and to capture the dependencies between the patient’s visits by employing multi-layer transformer blocks. Experiments conducted on two real-world healthcare datasets show that, our sequential diagnoses prediction model SETOR not only achieves better predictive results than previous stateof-the-art approaches, irrespective of sufﬁcient or insufﬁcient training data, but also derives more interpretable embeddings of medical codes. The experimental codes are available at the GitHub repository1.}, note={arXiv:2109.03069 [cs]}, number={arXiv:2109.03069}, publisher={arXiv}, author={Peng, Xueping and Long, Guodong and Shen, Tao and Wang, Sen and Jiang, Jing}, year={2021}, month=sep, language={en} }

@article{
paper-doctor-ai,
    title={Doctor AI: Predicting Clinical Events via Recurrent Neural Networks}, abstractNote={Leveraging large historical data in electronic health record (EHR), we developed Doctor AI, a generic predictive model that covers observed medical conditions and medication uses. Doctor AI is a temporal model using recurrent neural networks (RNN) and was developed and applied to longitudinal time stamped EHR data from 260K patients and 2,128 physicians over 8 years. Encounter records (e.g. diagnosis codes, medication codes or procedure codes) were input to RNN to predict (all) the diagnosis and medication categories for a subsequent visit. Doctor AI assesses the history of patients to make multilabel predictions (one label for each diagnosis or medication category). Based on separate blind test set evaluation, Doctor AI can perform diﬀerential diagnosis with up to 79% recall@30, signiﬁcantly higher than several baselines. Moreover, we demonstrate great generalizability of Doctor AI by adapting the resulting models from one institution to another without losing substantial accuracy.}, author={Choi, Edward and Bahadori, Mohammad Taha and Schuetz, Andy and Stewart, Walter F and Sun, Jimeng}, pages={18}, language={en} }

@article{
paper-multi-label,
  author={Zhang, Min-Ling and Zhou, Zhi-Hua}, journal={IEEE Transactions on Knowledge and Data Engineering}, title={A Review on Multi-Label Learning Algorithms}, year={2014}, volume={26}, number={8}, pages={1819-1837}, doi={10.1109/TKDE.2013.39}}

@article{
paper-lipton,
    added-at = {2018-11-21T00:00:00.000+0100}, author = {Lipton, Zachary C.}, biburl = {https://www.bibsonomy.org/bibtex/25e0657b768a4829a518ae94b1a1a789b/dblp}, ee = {https://doi.org/10.1145/3233231}, interhash = {570f1885f8d1e4a9f49bf69b5c031cca}, intrahash = {5e0657b768a4829a518ae94b1a1a789b}, journal = {Commun. ACM}, keywords = {dblp}, number = 10, pages = {36-43}, timestamp = {2018-11-22T11:37:41.000+0100}, title = {The mythos of model interpretability.}, url = {http://dblp.uni-trier.de/db/journals/cacm/cacm61.html#Lipton18}, volume = 61, year = 2018 }

@misc{
paper-adamw,
      title={Decoupled Weight Decay Regularization}, author={Ilya Loshchilov and Frank Hutter}, year={2019}, eprint={1711.05101}, archivePrefix={arXiv}, primaryClass={cs.LG} }

@article{
paper-shickel-ehr-survey,
    title={Deep EHR: a survey of recent advances in deep learning techniques for electronic health record (EHR) analysis}, author={Shickel, Benjamin and Tighe, Patrick James and Bihorac, Azra and Rashidi, Parisa}, journal={IEEE journal of biomedical and health informatics}, volume={22}, number={5}, pages={1589--1604}, year={2017}, publisher={IEEE} }

@article{
paper-rmsnorm,
    title={Root Mean Square Layer Normalization}, url={http://arxiv.org/abs/1910.07467}, note={arXiv:1910.07467 [cs, stat]}, number={arXiv:1910.07467}, publisher={arXiv}, author={Zhang, Biao and Sennrich, Rico}, year={2019}, month=oct, language={en} }

 @article{
 xai-survey,
     title={Benchmarking and Survey of Explanation Methods for Black Box Models}, url={http://arxiv.org/abs/2102.13076}, abstractNote={The widespread adoption of black-box models in Artiﬁcial Intelligence has enhanced the need for explanation methods to reveal how these obscure models reach speciﬁc decisions. Retrieving explanations is fundamental to unveil possible biases and to resolve practical or ethical issues. Nowadays, the literature is full of methods with diﬀerent explanations. We provide a categorization of explanation methods based on the type of explanation returned. We present the most recent and widely used explainers, and we show a visual comparison among explanations and a quantitative benchmarking.}, note={arXiv:2102.13076 [cs]}, number={arXiv:2102.13076}, publisher={arXiv}, author={Bodria, Francesco and Giannotti, Fosca and Guidotti, Riccardo and Naretto, Francesca and Pedreschi, Dino and Rinzivillo, Salvatore}, year={2021}, month=feb, language={en} }

@book{
tibsharani-elements,
    added-at = {2008-05-16T16:17:42.000+0200}, address = {New York, NY, USA}, author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome}, biburl = {https://www.bibsonomy.org/bibtex/2f58afc5c9793fcc8ad8389824e57984c/sb3000}, interhash = {d585aea274f2b9b228fc1629bc273644}, intrahash = {f58afc5c9793fcc8ad8389824e57984c}, keywords = {ml statistics}, publisher = {Springer New York Inc.}, series = {Springer Series in Statistics}, timestamp = {2008-05-16T16:17:43.000+0200}, title = {The Elements of Statistical Learning}, year = 2001 }


@article{
trees-breiman,
    title={Classification and Regression Trees}, author={L. Breiman and Jerome H. Friedman and Richard A. Olshen and C. J. Stone}, journal={Biometrics}, year={1984}, volume={40}, pages={874}, url={https://api.semanticscholar.org/CorpusID:29458883} }

@article{
attention-not-explanation,
    title={Attention is not Explanation}, url={http://arxiv.org/abs/1902.10186}, abstractNote={Attention mechanisms have seen wide adoption in neural NLP models. In addition to improving predictive performance, these are often touted as affording transparency: models equipped with attention provide a distribution over attended-to input units, and this is often presented (at least implicitly) as communicating the relative importance of inputs. However, it is unclear what relationship exists between attention weights and model outputs. In this work we perform extensive experiments across a variety of NLP tasks that aim to assess the degree to which attention weights provide meaningful “explanations" for predictions. We ﬁnd that they largely do not. For example, learned attention weights are frequently uncorrelated with gradient-based measures of feature importance, and one can identify very different attention distributions that nonetheless yield equivalent predictions. Our ﬁndings show that standard attention modules do not provide meaningful explanations and should not be treated as though they do. Code to reproduce all experiments is available at https://github.com/successar/ AttentionExplanation.}, note={arXiv:1902.10186 [cs]}, number={arXiv:1902.10186}, publisher={arXiv}, author={Jain, Sarthak and Wallace, Byron C.}, year={2019}, month=may, language={en} }

@article{
difficult-rnn,
    title={On the diﬃculty of training recurrent neural networks}, abstractNote={There are two widely known issues with properly training recurrent neural networks, the vanishing and the exploding gradient problems detailed in Bengio et al. (1994). In this paper we attempt to improve the understanding of the underlying issues by exploring these problems from an analytical, a geometric and a dynamical systems perspective. Our analysis is used to justify a simple yet effective solution. We propose a gradient norm clipping strategy to deal with exploding gradients and a soft constraint for the vanishing gradients problem. We validate empirically our hypothesis and proposed solutions in the experimental section.}, author={Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua}, language={en} }

@article{
gated-networks,
    title={Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling}, url={http://arxiv.org/abs/1412.3555}, abstractNote={In this paper we compare different types of recurrent units in recurrent neural networks (RNNs). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated recurrent unit (GRU). We evaluate these recurrent units on the tasks of polyphonic music modeling and speech signal modeling. Our experiments revealed that these advanced recurrent units are indeed better than more traditional recurrent units such as tanh units. Also, we found GRU to be comparable to LSTM.}, note={arXiv:1412.3555 [cs]}, number={arXiv:1412.3555}, publisher={arXiv}, author={Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua}, year={2014}, month=dec, language={en} }

@article{
attention-translation,
    title={Neural Machine Translation by Jointly Learning to Align and Translate}, url={http://arxiv.org/abs/1409.0473}, abstractNote={Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder–decoders and encode a source sentence into a ﬁxed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a ﬁxed-length vector is a bottleneck in improving the performance of this basic encoder–decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.}, note={arXiv:1409.0473 [cs, stat]}, number={arXiv:1409.0473}, publisher={arXiv}, author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua}, year={2016}, month=may, language={en} }

@article{
attention-all-need,
    title={Attention is All you Need}, author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia}, language={en} }

@article{
llama,
    title={LLaMA: Open and Efficient Foundation Language Models}, url={http://arxiv.org/abs/2302.13971}, abstractNote={We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community1.}, note={arXiv:2302.13971 [cs]}, number={arXiv:2302.13971}, publisher={arXiv}, author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timothée and Rozière, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and Joulin, Armand and Grave, Edouard and Lample, Guillaume}, year={2023}, month=feb, language={en} }

@article{
llama-2,
    title={Llama 2: Open Foundation and Fine-Tuned Chat Models}, abstractNote={In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our models outperform open-source chat models on most benchmarks we tested, and based on our human evaluations for helpfulness and safety, may be a suitable substitute for closedsource models. We provide a detailed description of our approach to fine-tuning and safety improvements of Llama 2-Chat in order to enable the community to build on our work and contribute to the responsible development of LLMs.}, author={Touvron, Hugo and Martin, Louis and Stone, Kevin}, language={en} }

@article{
transformer-approx,
    title={Are Transformers universal approximators of sequence-to-sequence functions?}, url={http://arxiv.org/abs/1912.10077}, abstractNote={Despite the widespread adoption of Transformer models for NLP tasks, the expressive power of these models is not well-understood. In this paper, we establish that Transformer models are universal approximators of continuous permutation equivariant sequence-to-sequence functions with compact support, which is quite surprising given the amount of shared parameters in these models. Furthermore, using positional encodings, we circumvent the restriction of permutation equivariance, and show that Transformer models can universally approximate arbitrary continuous sequence-to-sequence functions on a compact domain. Interestingly, our proof techniques clearly highlight the different roles of the self-attention and the feed-forward layers in Transformers. In particular, we prove that ﬁxed width self-attention layers can compute contextual mappings of the input sequences, playing a key role in the universal approximation property of Transformers. Based on this insight from our analysis, we consider other simpler alternatives to selfattention layers and empirically evaluate them.}, note={arXiv:1912.10077 [cs, stat]}, number={arXiv:1912.10077}, publisher={arXiv}, author={Yun, Chulhee and Bhojanapalli, Srinadh and Rawat, Ankit Singh and Reddi, Sashank J. and Kumar, Sanjiv}, year={2020}, month=feb, language={en} }
     
@article{
transformer-turing,
    title={On the Turing Completeness of Modern Neural Network Architectures}, url={http://arxiv.org/abs/1901.03429}, abstractNote={Alternatives to recurrent neural networks, in particular, architectures based on attention or convolutions, have been gaining momentum for processing input sequences. In spite of their relevance, the computational properties of these alternatives have not yet been fully explored. We study the computational power of two of the most paradigmatic architectures exemplifying these mechanisms: the Transformer (Vaswani et al., 2017) and the Neural GPU (Kaiser & Sutskever, 2016). We show both models to be Turing complete exclusively based on their capacity to compute and access internal dense representations of the data. In particular, neither the Transformer nor the Neural GPU requires access to an external memory to become Turing complete. Our study also reveals some minimal sets of elements needed to obtain these completeness results.}, note={arXiv:1901.03429 [cs, stat]}, number={arXiv:1901.03429}, publisher={arXiv}, author={Pérez, Jorge and Marinković, Javier and Barceló, Pablo}, year={2019}, month=jan, language={en} }

@article{
gans,
    title={Generative Adversarial Networks}, url={http://arxiv.org/abs/1406.2661}, abstractNote={We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.}, note={arXiv:1406.2661 [cs, stat]}, number={arXiv:1406.2661}, publisher={arXiv}, author={Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua}, year={2014}, month=jun, language={en} }

@article{
variational-autoencoders,
    title={An Introduction to Variational Autoencoders}, volume={12}, ISSN={1935-8237, 1935-8245}, DOI={10.1561/2200000056}, abstractNote={Variational autoencoders provide a principled framework for learning deep latent-variable models and corresponding inference models. In this work, we provide an introduction to variational autoencoders and some important extensions.}, note={arXiv:1906.02691 [cs, stat]}, number={4}, journal={Foundations and Trends® in Machine Learning}, author={Kingma, Diederik P. and Welling, Max}, year={2019}, pages={307–392}, language={en} }

@article{
dall-e,
    title={Improving Image Generation with Better Captions}, abstractNote={We show that prompt following abilities of text-to-image models can be substantially improved by training on highly descriptive generated image captions. Existing text-to-image models struggle to follow detailed image descriptions and often ignore words or confuse the meaning of prompts. We hypothesize that this issue stems from noisy and inaccurate image captions in the training dataset. We address this by training a bespoke image captioner and use it to recaption the training dataset. We then train several text-to-image models and find that training on these synthetic captions reliably improves prompt following ability. Finally, we use these findings to build DALL-E 3: a new text-to-image generation system, and benchmark its performance on an evaluation designed to measure prompt following, coherence, and aesthetics, finding that it compares favorably to competitors. We publish samples and code for these evaluations so that future research can continue optimizing this important aspect of text-to-image systems.}, author={Betker, James and Goh, Gabriel and Jing, Li and Brooks, Tim and Wang, Jianfeng and Li, Linjie and Ouyang, Long and Zhuang, Juntang and Lee, Joyce and Guo, Yufei and Manassra, Wesam and Dhariwal, Prafulla and Chu, Casey and Jiao, Yunxin and Ramesh, Aditya}, language={en} }

@article{
wgans,
    title={Wasserstein GAN}, url={http://arxiv.org/abs/1701.07875}, abstractNote={We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to other distances between distributions.}, note={arXiv:1701.07875 [cs, stat]}, number={arXiv:1701.07875}, publisher={arXiv}, author={Arjovsky, Martin and Chintala, Soumith and Bottou, Léon}, year={2017}, month=dec, language={en} }

