\documentclass[]{marticle}
\usepackage{mstyle}

\title{\vspace{-2cm}\textbf{\huge Predicting and Explaining on Electronic Health Records  with Transformer-based Models: a use case}}
\date{}
\author{}


\begin{document}
\maketitle


\textbf{Candidato:} Alessio Marchetti

\textbf{Relatori:} Roberto Pellungrini, Fosca Giannotti
\vspace{0.5cm}

The rapid growth of information systems in the healthcare sector has made large amounts of relevant
data available in the last decades. The abundance of medical records facilitates the development of
powerful AI tools capable of supporting physicians in diagnostics tasks. Good predictive models are
not enough though. Models as critical as those in the healthcare sector need to be interpretable and
explainable for healthcare experts. Thus explainability has become one of the most important topics
in the modern machine-learning research landscape.

In this thesis we study and improve upon an explainable AI system for sequential healthcare records,
doctorXAI. We improve on the underlying recurrent machine learning model with a transformer-based
solution, then we propose new generative methods to enhance the explanation produced by the system.
Finally we analyse the output of the system finding interesting correlations between the attention
of the transformer and the produced explanation.

\end{document}

